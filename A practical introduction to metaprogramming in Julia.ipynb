{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A practical introduction to metaprogramming in Julia\n",
    "\n",
    "**Andy Ferris**, *JuliaCon 2018*\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the JuliaCon 2018 workshop on metaprogramming!\n",
    "\n",
    "This is an Jupyter notebook. It contains a mixture of static text and interactive code. The Jupyter notebook is connected to  a fully-fledged instance of Julia (the \"kernel\"), so you can execute any code like you would at the REPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Use shift-enter to evaluate cell\n",
    "\n",
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to type and execute whatever you want\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code blocks as you follow along with the tutorial below. There will be exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In many programming environments, user friendliness must be traded of with execution speed. Using abstractions or “generic” code may come with a run-time overhead. Avoiding abstract or generic code exposes the user to underlying details that they may not care about, making code harder to read and reason about at a higher level, reducing programmer productivity. Often two languages are even employed - one for rapid prototyping, and one for deployment.\n",
    "\n",
    "It doesn’t have to be this way. The Julia language has been carefully constructed to allow for many common abstractions to be dealt with statically at compile time and have a have a zero run-time cost. This workshop will cover the topic of “metaprogramming” in Julia, which plays a large role in providing for low-cost abstractions and generic APIs. Traditionally, a “meta” program is logic which executes at compile time to help generate the code of a resulting program - that is, it is code that generates other code.\n",
    "\n",
    "In this workshop we will cover the building blocks of metaprogramming in Julia, starting with one of its core concepts - multiple dispatch, which in combination with the type system is itself is a Turing-complete computational environment. We will then begin working our way to more advanced topics such as traits, macros, constant propagation and generated functions, following approximately this order:\n",
    "\n",
    "* Multiple dispatch as a metaprogramming technique\n",
    "* Method inlining: faster than C?\n",
    "* Games with tuples: splatting, slurping and recursion\n",
    "* Dispatch revisited: interfaces and traits\n",
    "* Constant propagation (and what are `@pure` functions?)\n",
    "* Expressions and macros\n",
    "* Generated functions and when (not) to use them\n",
    "\n",
    "This workshop will attempt to be a pedagogical tutorial on how and when to use these techniques, full of practical examples I’ve seen in the wild or have used in my own code. Consideration will be given in how to use metaprogramming and still maintain a readable code base. Advice will also be provided on how to work with the compiler, and not against it, and how to make effective use of tools such as `@code_typed`. At the end of the workshop I hope you will have learned a technique or two that will help you to create generic, user-friendly APIs without sacrificing peak performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# How Julia works\n",
    "\n",
    "To understand how and when to apply metaprogramming techniques, it's important to gain an understanding of how the compiler works.\n",
    "\n",
    "Compilation in Julia can be broken down into a series of steps. Very roughly, the text you type at the REPL is turned into machine code through the following processes:\n",
    "\n",
    " 1. **Parsing:** Text like `f(x)` is converted from a simple stream of characters to *expressions*. Expressions are of type `Expr` and are a structured and normalized representation of the code, for example `Expr(:call, :f, :x)`. These surface-level expressions are a form of \"intermediate representaiton\" or IR of your code. Julia has multiple levels of IR as your code is processed from our high-level language to low-level machine code.\n",
    " \n",
    " 2. **Lowering:** The surface-level IR is transformed into so-called \"lowered\" IR through a series of syntactical transformations. These transformations mostly represent Julia's \"syntactic sugar\". For example, the expression for `a[i]` is transformed into the expression for `getindex(a, i)`. Broadcast fusion `f.(a .+ b)` as well as creation of closures are other examples of Julia's syntax \"sugar\".\n",
    "\n",
    "During the lowering stage, the compiler also populates the type tree and generic method tables. Afterwards, your program is semantically complete and \"ready to run\", and can be executed by an interpretter, such as *ASTInterpreter.jl*. This is the stage that \"precompilation\" ends and forms the contents of `.ji` files.\n",
    "\n",
    "However, by default Julia will perform many additional optimization steps to transform your code into fast machine code. The steps below should be viewed as optimizations and theoretically shouldn't *semantically* affect your program in any way.\n",
    "\n",
    " 3. **Inference and optimization:** At this point the IR is in a standardized form, and we can perform analysis and transformations on the code to make it faster. Chief amongst these optimizations is type inference and method resolution - the type of each expression is *inferred* by the compiler. When a function is called, inference will determine which method of that function is dispatched to, given the input types. It must then analyze that function to determine the return type. Constant propagation, branch pruning, inlining, and other optimizations also occur at this stage.\n",
    " \n",
    " 4. **LLVM code generation:** The resulting optimized, lowered Julia IR is then transformed to LLVM IR, which is a type of assembly language. LLVM will perform it's own set of optimizations on the assembly code.\n",
    " \n",
    " 5. **Native code generation:** LLVM will transform this into native machine code, placing each specialized method into memory that can be called (from any language) via a function pointer and following the C calling convention.\n",
    "\n",
    "Importantly, Julia provides powerful reflection tools to \"see\" what is happening at any of these stages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The surface-level expression for `1 + 1`. \n",
    "# Each `Expr` contains one \"head\" and many \"args\" (arguments). \n",
    "# For the case of `:call`, the first argument is the function being called\n",
    "dump(:(1 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is looking *inside* the + function, for `+(::Int64, ::Int64)`.\n",
    "# Internally, this calls another (built-in) function called `Base.add_int`\n",
    "@code_lowered 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference has marked the return type of `+(::Int64, ::Int64)` as `Int64`.\n",
    "# Base.add_int is a built-in function and cannot be optimized further.\n",
    "@code_typed 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the LLVM assembly for adding two `i64`s, using LLVM's built-in `add` function.\n",
    "@code_llvm 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the native x64 assembly for adding two signed 64-bit integers, using the `leaq` instruction.\n",
    "@code_native 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Feel free to explore code for some other functions you know. Press shift-enter to execute.\n",
    "# Some ideas: ==, <, push!, sin (with Int or Float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Multiple dispatch as a metaprogramming technique\n",
    "\n",
    "As we saw, Julia's inference engine will resolve method dispatch at compile-time. This gives us an opportunity to perform logic.\n",
    "\n",
    "Here we will first demonstrate that Julia's dispatch system is in-fact Turing complete. Here we are building our own binary machine, which we can do computations with at compile time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary representation at the type level - no run-time data!\n",
    "\n",
    "abstract type Bit; end\n",
    "\n",
    "struct Zero <: Bit; end\n",
    "struct One <: Bit; end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR and AND for two Bits\n",
    "\n",
    "Base.:|(::Zero, ::Zero) = Zero()\n",
    "Base.:|(::Zero, ::One)  = One()\n",
    "Base.:|(::One,  ::Zero) = One()\n",
    "Base.:|(::One,  ::One)  = One()\n",
    "\n",
    "Base.:&(::Zero, ::Zero) = Zero()\n",
    "Base.:&(::Zero, ::One)  = Zero()\n",
    "Base.:&(::One,  ::Zero) = Zero()\n",
    "Base.:&(::One,  ::One)  = One()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Bits make a Byte\n",
    "\n",
    "struct Byte{Bit1 <: Bit, Bit2 <: Bit, Bit3 <: Bit, Bit4 <: Bit, Bit5 <: Bit, Bit6 <: Bit, Bit7 <: Bit, Bit8 <: Bit}\n",
    "    bit1::Bit1\n",
    "    bit2::Bit2\n",
    "    bit3::Bit3\n",
    "    bit4::Bit4\n",
    "    bit5::Bit5\n",
    "    bit6::Bit6\n",
    "    bit7::Bit7\n",
    "    bit8::Bit8\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise OR and AND on Bytes\n",
    "\n",
    "function Base.:|(byte1::Byte, byte2::Byte)\n",
    "    return Byte(byte1.bit1 | byte2.bit1,\n",
    "                byte1.bit2 | byte2.bit2,\n",
    "                byte1.bit3 | byte2.bit3,\n",
    "                byte1.bit4 | byte2.bit4,\n",
    "                byte1.bit5 | byte2.bit5,\n",
    "                byte1.bit6 | byte2.bit6,\n",
    "                byte1.bit7 | byte2.bit7,\n",
    "                byte1.bit8 | byte2.bit8)\n",
    "end\n",
    "\n",
    "function Base.:&(byte1::Byte, byte2::Byte)\n",
    "    return Byte(byte1.bit1 & byte2.bit1,\n",
    "                byte1.bit2 & byte2.bit2,\n",
    "                byte1.bit3 & byte2.bit3,\n",
    "                byte1.bit4 & byte2.bit4,\n",
    "                byte1.bit5 & byte2.bit5,\n",
    "                byte1.bit6 & byte2.bit6,\n",
    "                byte1.bit7 & byte2.bit7,\n",
    "                byte1.bit8 & byte2.bit8)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform almost arbitrary logic on bits and bytes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte1 = Byte(Zero(), Zero(), One(),  Zero(), Zero(), One(), One(),  One())\n",
    "byte2 = Byte(Zero(), One(),  Zero(), Zero(), Zero(), One(), Zero(), One())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte1 | byte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte1 & byte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if type inference is doing the computation at compile-time\n",
    "\n",
    "@code_typed byte1 | byte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check if any logic at all is performed at run time\n",
    "\n",
    "@code_native byte1 | byte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a pointer to the singleton object - a compile-time constant\n",
    "\n",
    "unsafe_load(Base.unsafe_convert(Ptr{Ptr{Nothing}}, pointer_from_objref(Byte{Zero,One,One,Zero,Zero,One,One,One}) + 0x28)) # The 0x28 comes from the layout of DataType on x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# What other operations could you do in the type domain? Use your imagination!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a type in `Base` called `Val`\n",
    "# It lets you carry (immutable) data as a type parameter\n",
    "# You can then pass this data between functions as compile-time information.\n",
    "# WARNING: Only fast if the data is a compile-time constant!!\n",
    "\n",
    "Val(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turing Complete\n",
    "\n",
    "To make this Turing-complete, we need some way of creating \"memory\". One could use more `struct`s to build a heirarchy of words and pages of increasing number of bits, complete with a system of pointers and so-on!\n",
    "\n",
    "Alternatively, one can use the built-in `Tuple` type which can accept an arbitrary number of fields of different types. In either case, it is possible to perform just about any computation purely in the type domain.\n",
    "\n",
    "### Practical limitations on inference: the halting problem\n",
    "\n",
    "Julia is a friendly, interactive proramming environment. Code is being compiled and generated as users enter commands at the REPL or even during the normal execution of programs.\n",
    "\n",
    "To avoid horrible run-time crashes of the compiler itself, type inference must protect itself from doing arbitrarily complex logic which may never halt (or take too much RAM). It is quite easy to write a program which \"works\" but never ends - but it is not easy to determine exactly which programs will terminate without some level of approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that never ends\n",
    "\n",
    "never_ending_function(i::Int) = never_ending_function(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wonder what this does?\n",
    "\n",
    "never_ending_function(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type widening\n",
    "\n",
    "To deal with this challenge, the inference engine will only work with limited precision. In situations that may be potentially dangerous for the compiler - for example involving extremely complex types, or certain kinds of recursive function calls - the inference engine will intentially \"approximate\" its knowledge of the types to limit compile-time complexity. Inference may assign types \"wider\" than those deemed possible, but never narrower.\n",
    "\n",
    "This is an important feature of Julia's compiler and is rarely an issue in practice, if you know how to work with the compiler. \n",
    "\n",
    "### So, what now?\n",
    "\n",
    "The example above is a poor use of Julia's dispatch capabilities. Next we'll discuss some more useful dispatch scenarios you use every day in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Promotion\n",
    "\n",
    "Julia's `Base` library makes use of a *promotion system* so that working with and mixing together data of differnt types is simple and easy. For example, adding an integer to a floating point number automatically gives a floating point number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 3.14159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The promotion system is generic and fully-extensible to user-defined types. To promote two objects to the same type, we use the `promote` function, which returns a tuple with the two promoted objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promote(1, 3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like many functions in `Base`, when we invoke `+` with different types, promotion will be automatically invoked. Check out this method:\n",
    "\n",
    "```julia\n",
    "+(x::Number, y::Number) = +(promote(x,y)...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see this as a lowered expression, as well\n",
    "\n",
    "@code_lowered +(1, 3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how does `promote` work? For users, it is simple really - one just defines a `promote_rule` between two types. For example, one might define:\n",
    "\n",
    "```julia\n",
    "promote_rule(::Type{Float64}, ::Type{Int}) = Float64\n",
    "```\n",
    "\n",
    "One can do this with user-defined types and promotion will work automatically with many of `Base`s included functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE: enable addition for Bits - Zero and One\n",
    "\n",
    "Base.promote_rule(::Zero, ::One) = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is One + Zero?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is One + 3? (you might need more promote_rules...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Zero + Zero?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is One + One?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really neat and easy-to-use interface for users and library developers to hook into!\n",
    "\n",
    "But - how does it **really** work?\n",
    "\n",
    "### Simplified promotion\n",
    "\n",
    "To avoid a few details (error handling, efficiently promoting more than two objects, etc), I'll demonstrate a simplified version called `promote2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function promote2(a, b)\n",
    "    T = promote_type2(typeof(a), typeof(b))\n",
    "    return (convert(T, a), convert(T,b))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If two types are the same, no rule is needed\n",
    "promote_type2(::Type{T}, ::Type{T}) where {T} = T\n",
    "\n",
    "function promote_type2(::Type{T1}, ::Type{T2}) where {T1, T2}\n",
    "    T3 = promote_rule(T1, T2)\n",
    "\n",
    "    # It is OK if the user specified the rule one way but not the other\n",
    "    if T3 === Union{}\n",
    "        return promote_rule(T2, T1)\n",
    "    else\n",
    "        return T3\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promote2(1, 3.14159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed promote2(1, 3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promotion is a simple yet effective example of metaprogramming that\n",
    "\n",
    " 1. Is friendly for end-users\n",
    " 2. Is generic and extensible\n",
    " 3. Has zero run-time overhead\n",
    "\n",
    "These magic combination of factors is what we'll be chasing for the remainder of the workshop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Method inlining: Faster than C?\n",
    "\n",
    "In many languages, there is a run-time cost of adding many layers of indirection and dispatch.\n",
    "\n",
    "Julia's compiler will automatically *inline* certain functions, when:\n",
    "\n",
    " * The function body is small, such that the run-time cost of a new stack frame is signficant in comparison.\n",
    " * The function has no side effects and returns a type or a constant that can be inferred. In this case the function call is replaced by the type or constant.\n",
    " \n",
    "These pragmatic choices generally lead to good performance.\n",
    "\n",
    "The automatic behavior can be controlled with the macros `@inline` and `@noinline`. There are certain situations where you might like to use these\n",
    "\n",
    " * Using `@inline` can force some computations and simplifications to occur at compile time, and may be useful for your metaprogramming constructs. \n",
    " * Occassionally, using `@noinline` may help you avoid large function bodies or harmful \"optimizations\" that may result in worse performance.\n",
    " * `@noinline` is useful for creating benchmarking code (avoiding the situation where the compiler may elide what you are trying to measure).\n",
    " * Micro-optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A version of + that uses promote2\n",
    "\n",
    "add2(x,y) = +(promote2(x,y)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promote2, promote_type2, promote_rule and convert are all inlined and optimized away\n",
    "\n",
    "@code_typed add2(1, 3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method inlining can make a significant difference to performance. Traditional C and C++ compiler implementations often perform inlining as a \"link-time optimization\" (LTO) where generated code is inlined. Julia performs inlining at a higher level of IR where a greater amount of semantic information about the code is retained, leading to further optimizations opportunities (we will discuss the interplay between inlining, constant propagation and inference later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@noinline function promote3(a, b)\n",
    "    T = promote_type2(typeof(a), typeof(b))\n",
    "    return (convert(T, a), convert(T,b))\n",
    "end\n",
    "\n",
    "add3(x,y) = +(promote3(x,y)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark add2($1, $3.14159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark add3($1, $3.14159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  Games with tuples: splatting, slurping and recursion\n",
    "\n",
    "Some functions in Julia accept a variable number of arguments - so called \"varags\" functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+(1,2,3,4,5,6,7,8,9,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slurping\n",
    "\n",
    "A function can \"slurp\" up its (tail) arguments into a tuple using the `...`.\n",
    "\n",
    "(Note that `...` is also used for the inverse operation, called \"splatting\", which we will discuss below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function \"slurps\" up all of it's inputs and places them into a tuple called x\n",
    "slurp(x...) = x\n",
    "\n",
    "f(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also specify the type of the variable arguments\n",
    "slurp(x::Integer...) = x\n",
    "\n",
    "# In this case, the ... is syntactic sugar for a Vararg type\n",
    "slurp(x::Vararg{Integer}) = x\n",
    "\n",
    "# You can even specify the number of arguments as the second type parameter to Vararg\n",
    "# Frequently this will be free parameter (but it can also be a constant)\n",
    "slurp(x::Vararg{Integer, N}) where {N} = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Explore the different signatures of `slurp` we just created, using `methods`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function signature can contain other arguments before the varargs.\n",
    "\n",
    "```julia\n",
    "map(f, x1, x2, xs...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a method signature, anyway?\n",
    "\n",
    "A generic function can have many methods.\n",
    "\n",
    "Each method has a signature, which is represented by a (possibly abstract) `Tuple` type, like `Tuple{Integer, Integer}`. The `Tuple` type is unique in Julia in that it's parameters are *covariant* - for example `Tuple{Int64, Int32}` is a subtype of `Tuple{Integer, Integer}`.\n",
    "\n",
    "By default, a method is invoked with a precise (concrete) set of types, like `Tuple{Int64, Int32}`. These **specialized** methods are indivually optimized, inferred and compiled to machine code.\n",
    "\n",
    "### `Varargs` and `NTuple`\n",
    "\n",
    "We can also talk about `Tuple`s of variable length, most commonly known through the `NTuple{N, T}` type. Sometimes this is just convenient shorthand, like `NTuple{3, Float64}` is shorter to write than `Tuple{Float64, Float64, Float64}`.\n",
    "\n",
    "In other cases we want to be able to accept tuples of variable lengths, sometimes with restrictions like\n",
    "\n",
    "```julia\n",
    "map(f, t1::NTuple{N}, t2::NTuple{N}) where {N}\n",
    "```\n",
    "which accepts any two tuples so long as they have the same length.\n",
    "\n",
    "Fun fact:\n",
    "\n",
    "> The `NTuple{N, T}` type is actually a simple *alias* of the type `Tuple{Vararg{T, N}}`!\n",
    "\n",
    "This provides a direct link between a varargs function signatures such as `f(::Integer...)` and the signature type `Tuple{Vararg{Integer}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTuple{3, Integer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuple{Vararg{Integer, 3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuple{Vararg{Integer}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like a function signature, their may be other types before the varargs\n",
    "\n",
    "Tuple{String, Symbol, Float64, Vararg{Integer}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splatting\n",
    "\n",
    "One can perform the reverse operation, and \"splat\" a variable number of arguments into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (2, 3)\n",
    "*(x...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can splat out arguments into tuples, such as\n",
    "\n",
    "```julia\n",
    "append(t1::Tuple, t2::Tuple) = (t1..., t2...)\n",
    "```\n",
    "\n",
    "**Note:** Splatting is not limited to tuples - it is a generic iterator concept, relying on `iterate`, and can occur in other contexts like array literals, `[x\n",
    "\n",
    "Combining splatting and slurping can be very powerful. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `head` returns the first element of a tuple\n",
    "\n",
    "head(t::Tuple) = t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Create a `tail` function that returns all but the first argument of a tuple\n",
    "# Hint: begin with `tail(x::Tuple) = _tail(x...)` and define a suitable method for `_tail`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursion with tuples\n",
    "\n",
    "Splatting and slurping can be used to perform various recursive algorithms over tuples.\n",
    "\n",
    "Take for example a possible implementation of `map` (called `map2`). In this pattern we split appart out tuple using splatting, and work on it element-by element recursively using an inner helper function called `_map2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2(f, t::Tuple) = _map2(f, t...)\n",
    "\n",
    "# If the tuple is empty we return an empty tuple\n",
    "_map2(f) = ()\n",
    "\n",
    "# Otherwise we map the first element and apply _map to the remainder\n",
    "_map2(f, x, y...) = (f(x), _map2(f, y...)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2(-, (1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be more than one way to write this function using recursive methods.\n",
    "\n",
    "The advantage of the method shown is that each subsequent call to `_map2` is getting simpler and simpler until `_map2(f)` is called.\n",
    "\n",
    "When recursive function calls are made and are recursively becoming *more* complex, type inference may invoke widening to protect itself, resulting in sub-optimal code. It is recommended to take great care when using recursive methods.\n",
    "\n",
    "Next we do some excersises! Next, use a similar pattern to perform a reduction over a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Write a function `sum2` which adds all the elements of the tuple.\n",
    "\n",
    "sum2(t::Tuple) = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case\n",
    "sum2((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case\n",
    "sum2((1,2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTENSION EXERCISE\n",
    "\n",
    "# Create a more generic `reduce2` (or `mapreduce2`) function that works recursively over a tuple\n",
    "function reduce2(f, t::Tuple)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case\n",
    "reduce2(*, (1,2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTENSION EXERCISE\n",
    "\n",
    "# Create a method for `map2` which works on 2 input tuples, like `map2(+, (1,2,3), (4,5,6)) == (5,7,9)`\n",
    "# Hint: one possible solution would take advantage of the `head` and `tail` functions written earlier...\n",
    "\n",
    "function map2(f, t1::Tuple{Vararg{N}}, t2::Tuple{Vararg{N}}) where N  # N ensures tuples are of same length\n",
    "    ...\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case\n",
    "map2(+, (1,2,3), (4,5,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlining and recursion\n",
    "\n",
    "Method inlining plays an important role in recursive algorithms.\n",
    "\n",
    "Without inlining, a recursive algorithm on a tuple of length `N` is *O*(`N^2`). In the intermediate stages, *O*(`N`) tuples with average length *O*(`N`) are constructed and passed as arguments to the next function. The overhead in creating all those stack frames is enormous.\n",
    "\n",
    "In general - this kind of recursion is a **terrible algorithm**!\n",
    "\n",
    "In Julia, we sometimes use this pattern because combined with inlining and compiler optimizations to handle slurping and splatting, the run-time cost is only *O*(`N`) and this can be a convenient way to deal with data of different types at maximum speed. However - it is still may be hard work for the compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark map2(-, $(ntuple(identity, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark map2(-, $(ntuple(identity, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark map2(-, $(ntuple(identity, 33)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not careful - there is a huge performance cliff!\n",
    "\n",
    "With more than 32 elements, inference gives up on tracking the size of the tuples, and inlining the recursive function calls is disabled.\n",
    "\n",
    "For more complicated recursive functions, you may also want to invoke `@inline` to force the recursion to unroll (which will only work so long as the types are fully inferred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Constant propagation - and what are `@pure` functions?\n",
    "\n",
    "One of the optimizations performed by the compiler is \"constant\" propagation.\n",
    "\n",
    "### What's a constant?\n",
    "\n",
    "Values are \"constant\" if they are known to the compiler. These include\n",
    "\n",
    " * Literals like `true`, `1`, `3.0` or `:symbol`\n",
    " * Any known type\n",
    " * Any known type parameter\n",
    " * Any singleton object of a known type (i.e. a `struct` with no fields)\n",
    " * Other constants determined by the compiler\n",
    " \n",
    "The compiler can determine constants from other constants in a number of ways\n",
    "\n",
    " * Tuples can be constructed from constants, `t = (a, b)` where `a` and `b` are known.\n",
    " * Constant tuples can be indexed, splatted or slurped with other constants, `t[1]`, `t2 = (t..., c)`, etc.\n",
    " * Getting a field of a constant `struct`\n",
    " * Functions that are computable from the type signature alone, like `length(::Tuple{Vararg{Any, N}}) where {N} = N`\n",
    " * Functions that are marked `@pure` and have constant inputs.\n",
    " * `===` between two constants or known types\n",
    " * Some other in-built functions that have constant inputs, like `Base.add_int(1, 2)`\n",
    " * ...\n",
    " \n",
    "This is a growing list, as the compiler evolves and improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function where we can infer the output\n",
    "\n",
    "constant_function() = 1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the compiler do?\n",
    "\n",
    "@code_typed constant_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant propagation is particularly useful for collapsing nested calls of functions\n",
    "\n",
    "outer_function() = constant_function() + constant_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is essentially a form of inlining\n",
    "\n",
    "@code_typed outer_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if the input is not constant, the output might be!\n",
    "\n",
    "constant_function2(x) = 1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed constant_function2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if the function is impure, it's return value might be known by the compiler\n",
    "\n",
    "function impure_constant_function(x)\n",
    "    x[1] = 1 + 2\n",
    "    return 1 + 2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed impure_constant_function([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all operations will propagate values automatically\n",
    "\n",
    "not_constant_function() = 1 + pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that floating-point addition will not propagate constants by default\n",
    "# NOTE: Probably a good thing!\n",
    "\n",
    "@code_typed not_constant_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and type parameters\n",
    "\n",
    "Types and their parameters are also compile-time constant values.\n",
    "\n",
    "This works both ways\n",
    "\n",
    " * Extracting a type parameter results in a constant\n",
    " * Type inference can only succeed when type parameters are constant values (or known types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type parameters can be inferred from constant values\n",
    "\n",
    "impure_constant_function2(x) = Val(impure_constant_function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed impure_constant_function2([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A type parameter that depends on a variable\n",
    "\n",
    "not_const_function2(x) = Val(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's no way to fully determine the type from variable `x`\n",
    "\n",
    "@code_typed not_const_function2(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `@pure` functions\n",
    "\n",
    "A function can be marked as `@pure` as an assertion to the compiler that it may be invoked at compiler-time with no side effects.\n",
    "\n",
    "Note that `Base.@pure` is not exported by default. If you need it you can `import` it or specify it fully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark this function as `@pure`\n",
    "\n",
    "Base.@pure pure_function(x) = 1 + pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `@pure` functions behave like normal functions...\n",
    "\n",
    "@code_typed pure_function(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... unless they are called from another function with constant inputs\n",
    "\n",
    "call_pure_function() = pure_function(1)\n",
    "\n",
    "@code_typed call_pure_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beware**\n",
    "\n",
    "There are severe limitations on the capabilities of `@pure` functions!\n",
    "\n",
    "Earlier we said that `@pure` is\n",
    "\n",
    "> an assertion to the compiler that it may be invoked at compiler-time with no side effects.\n",
    "\n",
    "In Julia, many statements have side effects on the state of the compiler itself. Every time a new type or method is defined, the state of the compiler changes to reflect the new information. The current state of the type system and method tables is called the \"world\". Every time the world changes, the \"world age\" increments. If methods are overwritten or specialized, other methods may also change.\n",
    "\n",
    "The compiler will assume that a `@pure` function will not change *in any way* as the world age is incremented. It will not be recompiled to deal with new methods and you will encounter a \"world age error\" if it attempts to perform dispatch based on new types.\n",
    "\n",
    "Thus - `@pure` functions are **not suitable for use in most situations**. It may be safe in cases where the input types are fully specified and the dependent function calls are very basic. In most situations it is better to use constant propagation.\n",
    "\n",
    "***You have been warned!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-procedural constant propagation\n",
    "\n",
    "Typically, functions (not marked as `@pure`) are specialized on their input types alone. Constants will only propagate within the scope of the method (or as a return value, if it can be evaluated).\n",
    "\n",
    "Sometimes, it is useful to optimize the cases where some but not all the inputs are constant. Julia indirectly supports this by supporting constant propagation through function barriers when the function is inlined.\n",
    "\n",
    "Enforcing inlining to allow constant propagation may be a valid use for `@inline`. This is particularly useful if the return type depends on an input parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inline function firstchar(str::String, return_char::Bool = true)\n",
    "    if return_char\n",
    "        return str[1]\n",
    "    else\n",
    "        return String(str[1])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `getproperty` overloading\n",
    "\n",
    "New to Julia v0.7 is the ability to overload the `getproperty` function, where `a.b` is syntactic sugar for `getproperty(a, :b)`. The default definition is similar to:\n",
    "\n",
    "```julia\n",
    "getproperty(x, f::Symbol) = getfield(x, f)\n",
    "```\n",
    "where `getfield` accesses directly a field in a `struct` or `mutable struct`.\n",
    "\n",
    "`getproperty` relies on constant propagation for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Define `getproperty` for `Array` so that we can get it's length or size via `a.lenth` or `a.size`.\n",
    "\n",
    "@inline function Base.getproperty(a::Array, s::Symbol)\n",
    "    ...\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the return type can be correctly inferred\n",
    "\n",
    "function get_length(a::Array)\n",
    "    return a.length\n",
    "end\n",
    "\n",
    "@code_typed get_length([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Julia, it would not be usual to define complex properties in this way.\n",
    "\n",
    "Generally, I feel this is useful for:\n",
    "\n",
    " * defining a consistent *interface* across different related types (which might have different `struct` fields)\n",
    " * making types similar to `NamedTuple` which act as if they have user-definable field names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dispatch revisited: Interfaces and Traits\n",
    "\n",
    "Programming in Julia is organized around a tree of data types and a variety of extensible, generic functions.\n",
    "\n",
    "Generic functions can be overloaded with any number of methods. For some functions there is only one method, for others there are very many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(pwd) # prints working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(+) # Add's two or more objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# View the methods of some function you're interested in\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an interface?\n",
    "\n",
    "In theory, the methods of a function do not have to share any semantic similarity. From the language's perspective, there's nothing **wrong** with defining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(x::Int, y::Int) = x + y\n",
    "add(x::Float64, y::Float64) = x - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However - clearly this is a **bad** idea!\n",
    "\n",
    "This is because humans need to be able to read, reason about and write code - no matter the programming language or its rules. If you do this in the middle of your company's large piece of software, some poor programmer will get very confused, and your coworkers will get rather upset with you!\n",
    "\n",
    "Very loosely defined, when I say \"interface\" I mean the set of language and semantic guarantees surrounding how one or more generic functions behave for different sets of input types.\n",
    "\n",
    "Later, I'll define more precisely a concept of \"strong interface\" with the aim of defining what these guarantees exactly should be.\n",
    "\n",
    "But for now let's accept the following as good practice:\n",
    "\n",
    "> Given a generic function `f`, the meaning of `f(x::T)` should be consistent and predictable accross different types `T`.\n",
    "\n",
    "If this were not true, then a generic function `g` (which accepts a range of input types) would not be able to safely and reliably call `f` for all of *its* input types.\n",
    "\n",
    "And of course, the writer of `g` doesn't want it to crash for its users!\n",
    "\n",
    "**Case study:** `hash` and `isequal` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?isequal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strong Interface\n",
    "\n",
    "Unlike languages such as Go, Haskell and others, Julia doesn't have a *formal* way of specifying an interface. It is a gentlemen's agreement - or quite often a bit more like a pirate's accord.\n",
    "\n",
    "Take for example `AbstractArray{T, N}`. When I perform scalar `getindex` on any `AbstractArray{T}` I expect that I get a `T` back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [1, 2, 3]\n",
    "\n",
    "array[1] isa eltype(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I were to create my own array type that *lied* about it's element type, that would\n",
    "\n",
    " 1. Be bad. Many functions would crash.\n",
    " 2. Be perfectly allowable according to the formal rules of Julia.\n",
    "\n",
    "In order to have our library functions compose together and be extensible to new types, we must respect their respective interfaces. Generally, an interface is documented, like\n",
    "\n",
    "```julia\n",
    "\"\"\"\n",
    "    isbla(x)\n",
    "\n",
    "Return true if `x` is bla, and false otherwise.\n",
    "\"\"\"\n",
    "isbla(::Any) = false\n",
    "isbla(i::Integer) = iseven(i)\n",
    "isbla(::Complex) = true\n",
    "```\n",
    "\n",
    "What can we say about this function? Well, for one thing, it better return a `Bool`, since the documentation says it can return `true` or `false`. If you can figure out from the description what \"bla\" might mean, you might overload it for your own type.\n",
    "\n",
    "However, this still poses difficulty in some situations - what should `isbla(missing)` be? Given this docstring, users are likely to write code such as `if isbla(x); ...; else; ...; end`. However, if `isbla(::Missing) = missing` then this code will crash!\n",
    "\n",
    "To me, what I call a *strong* interface is one which favours **blind composition**. A library writer \"Alice\" is creating a method `f(::A)` and knows about a method `g(::A)`. A second author \"Bob\" creates type `B <: A` and creates a specialized method for `g(::B)`. To support blind composition, Bob's method `g(::B)` must satisfy everything about `g(::A)` that Alice can reasonably assume about its behavior and output. Generally, this might include:\n",
    "\n",
    " * Guarantees on the output type of `g(::A)` should be respected by `g(::B)`. This can be an abstract type - for example, `similar(::AbstractArray)` should always be an `AbstractArray`, or blind composition will not work.\n",
    " * Any semantic understanding of the behavior of `g(::A)`. We shouldn't write a method for `map` that only transforms the first element!\n",
    " * How `g` mutates it's input or has (relevant) side-effects. We shouldn't write a method for `map!` that only mutates it's first element!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all bad! Bad, bad, BAD!\n",
    "\n",
    "struct BadArray <: AbstractMatrix{Int}\n",
    "   data::Vector{Float64}\n",
    "end\n",
    "\n",
    "Base.getindex(a::BadArray, i...) = a.data[i...]\n",
    "Base.axes(a::BadArray) = axes(a.data)\n",
    "Base.size(a::BadArray) = size(a.data)\n",
    "\n",
    "Base.similar(a::BadArray) = Dict()\n",
    "Base.map!(f, a::BadArray) = (a[1] = f(a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Try to do literally *anything* with BadArray!\n",
    "\n",
    "BadArray([1.0, 2.5, 3.14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the most important feature of well designed interfaces is that they can be\n",
    "\n",
    " * extended\n",
    " * composed\n",
    " \n",
    "An interface might be extended by e.g. creating a subtype of `AbstractArray` that correctly defines `getindex`, `axes` and `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Vec3{T} <: AbstractVector{T}\n",
    "    data::Tuple{Float64, Float64, Float64}\n",
    "end\n",
    "\n",
    "Vec3(x::T, y::T, z::T) where {T} = Vec3{T}((x, y, z))\n",
    "\n",
    "Base.getindex(v::Vec3, i::Int) = v.data[i]\n",
    "Base.size(::Vec3) = (3,)\n",
    "Base.axes(::Vec3) = (Base.OneTo(3),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec3 = Vec3(1.0, 2.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traits\n",
    "\n",
    "Traits are properties of types that can be determined at compile-time and can be used to aid dispatch.\n",
    "\n",
    "One prominent example of a trait is `IndexStyle`, which controls if a multidimensional array will be more quickly indexed by a single, linear index (as if it were a dense array) or a set of Cartesian indices. In this case we can define the trait as\n",
    "\n",
    "```julia\n",
    "Base.IndexStyle(::Type{<:Vec3}) = IndexLinear()\n",
    "```\n",
    "\n",
    "There are multiple ways of defining indices, but one recommended pattern (used by `Base`) is:\n",
    "\n",
    " * Each trait class has a common abstract supertype, in this case `IndexStyle`\n",
    " * A trait can be determined by calling the constructor for the trait class with a type.\n",
    " * The returned trait is an instance, in this case `IndexLinear()`.\n",
    " \n",
    "Following this, one can construct a fairly simple dispatch pattern that takes account of the traits. In this case, this is *approximately*:\n",
    "\n",
    "```julia\n",
    "function getindex(a::AbstractArray, inds...)\n",
    "    _getindex(IndexStyle(typeof(a)), a, to_indices(a, inds)...)\n",
    "end\n",
    "```\n",
    "where `to_indices` expands any `:` to an index range for the relevant dimension.\n",
    "\n",
    "Now, we can define seperate methods for\n",
    "```julia\n",
    "function _getindex(::IndexLinear, a::AbstractArray, inds...)\n",
    "    ...\n",
    "end\n",
    "```\n",
    "and a different method for\n",
    "```julia\n",
    "function _getindex(::IndexCartesian, a::AbstractArray, inds...)\n",
    "    ...\n",
    "end\n",
    "```\n",
    "which may be faster for those kinds of arrays.\n",
    "\n",
    "In the above, the trait dispatch allows us to perform different implementations based on some property of the `AbstractArray`. Doing it this way has the following benefits:\n",
    "\n",
    " * `getindex` itself gives the same answer, not matter the array type.\n",
    " * An end user doesn't need to worry about the traits, only the library writer.\n",
    " * It still isn't one-size-fits all. There is more than one generic implementation.\n",
    " * We only need to write one scalar `getindex` method for each new array. Multiple `getindex` is fully automated, meaning we don't need to rewrite a whole bunch of code - resulting in faster, less buggy code.\n",
    " * Julia packages are free to define a new subtype of `IndexStyle` if its helpful.\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_lowered getindex(vec3, :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Expressions and macros\n",
    "\n",
    "Finally, we turn out attention to a more \"direct\" form of metaprogramming, where we directly interact with, and execute, Julia code expressions.\n",
    "\n",
    "### What's an expression?\n",
    "\n",
    "Well, there's *expressions*, and then there's `Expr`s.\n",
    "\n",
    " * Any valid piece of Julia code is an \"expression\".\n",
    " * All expressions have a type and a value.\n",
    " * There is no \"empty expression\", or `void`. The value `nothing::Nothing` is inserted by lowering when encountering empty blocks.\n",
    " * Any value can be an expression - typically literals, types or constants.\n",
    " * The name of a binding in-scope is a valid expression - consider `f(x) = x`. The expression for the right-hand-side is `:x`. The namespace of a symbol is discovered by lowering based on the scoping rules.\n",
    " * `Symbol`s can also themselves be values... for `f(x) = :x` the right-hand-side is `QuoteNode(:x)`.\n",
    " * There are a few other special expression objects, like `LineNumberNode` and so-on.\n",
    " * But, almost all complex, nested expressions are represented by the `Expr` type.\n",
    " \n",
    "One can create expressions using the following syntax\n",
    "\n",
    "```julia\n",
    ":( ... )\n",
    "```\n",
    "or\n",
    "```julia\n",
    "quote\n",
    "    ...\n",
    "end\n",
    "```\n",
    "Let's explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A literal value is still an expression - it doesn't need to be wrapped in a special wrapper type\n",
    "\n",
    ":(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":( my_variable )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `Expr` has a `head::Symbol` and a list of `args::Vector{Any}`.\n",
    "\n",
    "Let's explore some common cases. It is easier to view the elements of an `Expr` by calling `dump` to lay out it out as a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_expr = :(a.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expression head is the Symbol for \".\"\n",
    "\n",
    "my_expr.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first element is a reference to the binding in scope called \"a\"\n",
    "# The second element is a reference to the Symbol \":b\" - the name of the field\n",
    "\n",
    "my_expr.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see it easier using `dump`\n",
    "# The \"b\" part is wrapped in a `QuoteNode`\n",
    "\n",
    "dump(:(a.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some operators are directly translated to :call expressions \n",
    "\n",
    "dump(:(a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other operators get their own expression `head` type\n",
    "\n",
    "dump(:(a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quote blocks sometimes be a more convenient way of constructing an expression\n",
    "# By default, they insert line information about where the quote block is in the code\n",
    "\n",
    "quote\n",
    "    x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the surface level, `Expr`s with head `:block` are created by `begin ... end`\n",
    "\n",
    "dump(quote\n",
    "    x\n",
    "end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Explore some expressions you use. Examples: \n",
    "#  * if statements\n",
    "#  * for loop\n",
    "#  * getting and setting array elements\n",
    "#  * constructing arrays\n",
    "#  * constructing typed arrays\n",
    "\n",
    "dump(:( ... ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the expression look like for a macro call?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTENSION EXERCISE\n",
    "\n",
    "# Directly using the `Expr` constructor, create an expression for setting the index `i` of an array `a` to value `3`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating expressions via interpolation\n",
    "\n",
    "When metaprogramming, it is common to want to create expression programatically, where parts of the expression depend on some data you have.\n",
    "\n",
    "It is a little annoying to have to construct expressions fully-by hand. For example:\n",
    "\n",
    "```julia\n",
    "function expr_maker(i)\n",
    "    return Expr(:block, Expr(:=, Expr(:ref, :a, i), 3))\n",
    "end\n",
    "```\n",
    "\n",
    "To make life easier, Julia allows interpolation of values using `$`, directly into expressions.\n",
    "\n",
    "```julia\n",
    "function expr_maker(i)\n",
    "    return :( a[$i] = 3 )\n",
    "end\n",
    "```\n",
    "\n",
    "It is a **lot** easier to read the second version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make return the expression for a vector literal `[1, 2, 3, ..., n]` for variable `n`\n",
    "\n",
    "function make_vect1(n)\n",
    "    return Expr(:vect, 1:n...)\n",
    "end\n",
    "\n",
    "make_vect1(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same, using interpolation syntax\n",
    "\n",
    "function make_vect2(n)\n",
    "    return :( [$(1:n...)] )\n",
    "end\n",
    "\n",
    "make_vect2(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Do the same thing for tuple (1, 2, 3, ..., n)\n",
    "\n",
    "function make_tuple(n)\n",
    "    return ...\n",
    "end\n",
    "\n",
    "make_tuple(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macros\n",
    "\n",
    "Macros are special functions that transform expressions and insert the result back into your code.\n",
    "\n",
    "This can be useful for a variety of reasons.\n",
    "\n",
    " * A convenient way to \"annotate\" expressions, like `@inline f(x) = ...`\n",
    " * Provide tools that take expressions and use them for a task - `@time`, `@code_typed`, `@benchmark`, etc\n",
    " * Create a useful shortcut to save on typing - `Base.@nloops` makes arbitry number of nested loops\n",
    " * Create an entire DSL - like *Query.jl*, *Flux.jl*, etc.\n",
    "\n",
    "Macros are defined with the `macro` keyword:\n",
    "\n",
    "```julia\n",
    "macro negative(ex)\n",
    "    return :( - $ex )\n",
    "end\n",
    "```\n",
    "\n",
    "And called with an `@` symbol:\n",
    "\n",
    "```julia\n",
    "minus_one = @negative 1\n",
    "```\n",
    "\n",
    "The `@` is a signifier to the user (and parser) that a syntax transformation is occuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "macro negative(ex)\n",
    "    return :( - $ex )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_one = @negative 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2\n",
    "@negative x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro dispatch\n",
    "\n",
    "You can define multiple methods for a macro. However, they can only *dispatch* on the expression types.\n",
    "\n",
    "This is most useful for defining a macro of different *arity* (number of inputs). For example\n",
    "\n",
    "```julia\n",
    "macro m(ex)\n",
    "    # do something with one expression\n",
    "end\n",
    "\n",
    "macro m(ex1, ex2)\n",
    "    # do something with two expressions\n",
    "end\n",
    "```\n",
    "\n",
    "However, expressions do come in different types and it is perfectly valid define methods for different expression types - such as integer literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro superpower(i::Int)\n",
    "    return :($i ^ $i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@superpower 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@superpower 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This macro expects a integer literal value, not a variable name\n",
    "\n",
    "x = 3\n",
    "@superpower x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macros also gain access to some metadata about where they are called from and from which module (the first two arguments in the method error above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Generated functions and when (not) to use them\n",
    "\n",
    "The final metaprogramming technique that we will cover is `@generated` functions.\n",
    "\n",
    "Such functions represent a form of staged programming where code is created based on the input. \n",
    "\n",
    "To execute at full speed with Julia's compilation process, they are designed to generate code based on the *type* of the input arguments. If the code depended on run-time data, then that code would have to be compiled every time the function would be called! Thus, we are limited to the information available to type inference.\n",
    "\n",
    "Distinct code is generated for each unique, concrete function signature. You can see the generated code using `@code_lowered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generated function sum3(t::NTuple{N, Any}) where {N}\n",
    "    # This body is the \"function generator\"\n",
    "    elements = [ :( t[$i] ) for i = 1:N ]\n",
    "    expr = :( +($(elements...)) )\n",
    "    \n",
    "    return expr # The returned expression is the \"generated function body\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum3((1, 2.0, pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_lowered sum3((1, 2.0, pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_lowered sum3((1, 2, 3, 4, 5, 6, 7, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that there are several restrictions regarding generated functions\n",
    "\n",
    " * The compiler provides no guarantees whether the code generation is invoked one time, many times or even zero times (because of precompilation).\n",
    " * The code generator should have no side effects and has the same limitations as `@pure` functions.\n",
    " * The generated code cannot create new types. This means you can not generate code with closures (note: it is always possible to define your own closure type). This limitation also holds for generators and comprehensions.\n",
    " \n",
    "Together, these restrictions are quite strict. Some tips and observations:\n",
    "\n",
    " * Stick to very simple code generation primitives - like unrolling loops, etc.\n",
    " * Rely on inference and constant propagation as much as possible. For example, instead of using `promote_type` inside your function generator, emit it as generated code and let Julia calculate it as a part of the usual compilation process. This will avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXERCISE\n",
    "\n",
    "# Define a generated function that performs elementwise addition between two tuples\n",
    "\n",
    "@generated function add_tuples(t1::NTuple{N, Any}, t2::NTuple{N, Any}) where N\n",
    "    # Create expression\n",
    "    \n",
    "    # return expression\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case\n",
    "\n",
    "add_tuples((1, 2, 3), (2.2, 3.3, 4.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing remarks\n",
    "\n",
    "I hope you've learnt something new (and useful!) during this tutorial. My goals have been to:\n",
    "\n",
    " * Get you to interact with tools like `@code_lowered` and `@code_typed` so you can explore Julia yourselves\n",
    " * Have a working understanding of how the Julia compiler works\n",
    " * Explore the fundamental metaprogramming capabilites provided by Julia\n",
    " * Highlight the limitations of each approach\n",
    " * Have a bit of fun playing around\n",
    "\n",
    "I will finish with some general advice, from the perspective of a library writer:\n",
    "\n",
    " * As much as possible, try work with the natural compilation process - type inference, constant propagation and inlining.\n",
    " * Only intervene with macros, `@pure` functions and `@generated` functions when there is a compelling reason to do so.\n",
    " * Recursion works well for small sizes but is not suitable for large objects.\n",
    " * Use these powerful tools to make your API easier for the end user.\n",
    " * Try to maintain a minimal, generic and extensible interface. Blind composition with other libraries is key.\n",
    " * Macros are **not** extensible interfaces - they are one-trick ponies. (That can be OK!)\n",
    " * The metaprogramming magic should be invisible! (to users)\n",
    " * The metaprogramming magic should be readable... (to other developers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QUESTIONS?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0-beta2",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
